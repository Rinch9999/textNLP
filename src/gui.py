import streamlit as st
import os
import sys
import numpy as np
import pandas as pd
from preprocess import DataProcessor
from model import ModelTrainer
from visualization import Visualizer
import matplotlib.pyplot as plt
import seaborn as sns

class SentimentAnalyzerGUI:
    def __init__(self, models_dir='../models', results_dir='../results'):
        self.models_dir = models_dir
        self.results_dir = results_dir
        self.model_trainer = ModelTrainer()
        self.processor = None
        self.loaded_models = {}
        self.vectorizer = None
        
        # è®¾ç½®é¡µé¢é…ç½®
        st.set_page_config(
            page_title="å½±è¯„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ",
            page_icon="ğŸ¬",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.models_dir, exist_ok=True)
        os.makedirs(self.results_dir, exist_ok=True)
        
        # æå‰ä¸‹è½½nltkèµ„æº
        import nltk
        nltk.download('stopwords', quiet=True)
        nltk.download('punkt', quiet=True)
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
    
    def load_models(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œæ¨¡å‹ç›®å½•: {self.models_dir}")
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(self.models_dir, exist_ok=True)
            model_files = [f for f in os.listdir(self.models_dir) if f.endswith('.pkl')]
            print(f"æ‰¾åˆ°çš„æ¨¡å‹æ–‡ä»¶: {model_files}")
            for model_file in model_files:
                model_path = os.path.join(self.models_dir, model_file)
                model_name = os.path.splitext(model_file)[0]
                try:
                    model = self.model_trainer.load_model(model_path)
                    self.loaded_models[model_name] = model
                    print(f"æˆåŠŸåŠ è½½æ¨¡å‹: {model_name}")
                except Exception as e:
                    print(f"åŠ è½½æ¨¡å‹ {model_name} å¤±è´¥: {e}")
            print(f"å·²åŠ è½½æ¨¡å‹åˆ—è¡¨: {list(self.loaded_models.keys())}")
            # åŠ è½½å‘é‡izer
            processed_data_path = os.path.join(self.models_dir, 'processed_data.npz')
            print(f"æ­£åœ¨åŠ è½½å‘é‡izerï¼Œè·¯å¾„: {processed_data_path}")
            if os.path.exists(processed_data_path):
                data = np.load(processed_data_path, allow_pickle=True)
                self.vectorizer = data['vectorizer'].item()
                print("æˆåŠŸåŠ è½½å‘é‡izer")
            else:
                print(f"æœªæ‰¾åˆ°processed_data.npzæ–‡ä»¶: {processed_data_path}")
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    def preprocess_text(self, text, language='zh'):
        """é¢„å¤„ç†å•ä¸ªæ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡"""
        import re
        import jieba
        import nltk
        from nltk.corpus import stopwords
        
        # æ¸…æ´—æ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡
        def clean_text(text):
            text = re.sub(r'<[^>]+>', '', text)
            if language == 'zh':
                # ä¸­æ–‡ï¼šåªä¿ç•™ä¸­æ–‡
                text = re.sub(r'[^\u4e00-\u9fa5]', ' ', text)
            else:
                # è‹±æ–‡ï¼šåªä¿ç•™å­—æ¯
                text = re.sub(r'[^a-zA-Z]', ' ', text)
                text = text.lower()
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        
        text = clean_text(text)
        
        # æ ¹æ®è¯­è¨€é€‰æ‹©åˆ†è¯æ–¹æ³•
        if language == 'zh':
            # ä¸­æ–‡åˆ†è¯
            tokens = ' '.join(jieba.cut(text))
        else:
            # è‹±æ–‡åˆ†è¯
            tokens = nltk.word_tokenize(text)
            # å»é™¤åœç”¨è¯
            en_stop_words = set(stopwords.words('english'))
            tokens = [token for token in tokens if token not in en_stop_words]
            tokens = ' '.join(tokens)
        
        # å‘é‡åŒ–
        if self.vectorizer is not None:
            vector = self.vectorizer.transform([tokens]).toarray()
            return vector
        else:
            raise ValueError("å‘é‡izeræœªåŠ è½½")
    
    def predict_sentiment(self, text, model_name, language='zh'):
        """é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿï¼Œé™ä½é˜ˆå€¼æé«˜è´Ÿé¢å½±è¯„è¯†åˆ«ç‡"""
        if model_name not in self.loaded_models:
            return None, "æ¨¡å‹æœªæ‰¾åˆ°"
        
        try:
            # é¢„å¤„ç†æ–‡æœ¬
            vector = self.preprocess_text(text, language=language)
            
            # é¢„æµ‹
            model = self.loaded_models[model_name]
            if hasattr(model, 'predict_proba'):
                y_pred_proba = model.predict_proba(vector)[0][1]
            else:
                y_pred_proba = model.predict(vector)[0]
            
            # é™ä½é˜ˆå€¼ï¼Œæé«˜å¯¹è´Ÿé¢å½±è¯„çš„è¯†åˆ«ç‡
            threshold = 0.4
            y_pred = 1 if y_pred_proba > threshold else 0
            sentiment = "æ­£é¢" if y_pred == 1 else "è´Ÿé¢"
            confidence = y_pred_proba if y_pred == 1 else 1 - y_pred_proba
            
            return sentiment, confidence
        except Exception as e:
            return None, f"é¢„æµ‹å¤±è´¥: {e}"
    
    def display_results(self):
        """æ˜¾ç¤ºç»“æœé¡µé¢"""
        try:
            st.title("ğŸ¬ å½±è¯„æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
            st.markdown("---")
            
            # ä¾§è¾¹æ 
            st.sidebar.header("è®¾ç½®")
            
            # ç¡®ä¿æ¨¡å‹åˆ—è¡¨ä¸ä¸ºç©º
            if not self.loaded_models:
                st.sidebar.warning("æœªåŠ è½½åˆ°ä»»ä½•æ¨¡å‹")
                # æ·»åŠ é»˜è®¤æ¨¡å‹åˆ—è¡¨ï¼Œé¿å…å´©æºƒ
                self.loaded_models = {'logistic_regression': None, 'random_forest': None}
            
            model_name = st.sidebar.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                list(self.loaded_models.keys()),
                index=0
            )
            
            language = st.sidebar.radio(
                "é€‰æ‹©è¯­è¨€",
                ['ä¸­æ–‡', 'English'],
                index=0
            )
            language_code = 'zh' if language == 'ä¸­æ–‡' else 'en'
            
            # ä¸»é¡µé¢
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.header("è¾“å…¥å½±è¯„")
                user_input = st.text_area(
                    "è¯·è¾“å…¥å½±è¯„å†…å®¹",
                    height=200,
                    placeholder="ä¾‹å¦‚: è¿™éƒ¨ç”µå½±å‰§æƒ…ç´§å‡‘ï¼Œæ¼”å‘˜è¡¨æ¼”å‡ºè‰²ï¼Œéå¸¸æ¨èè§‚çœ‹ï¼"
                )
                
                if st.button("ğŸ¯ åˆ†ææƒ…æ„Ÿ", type="primary", use_container_width=True):
                    if user_input.strip():
                        with st.spinner("æ­£åœ¨åˆ†æ..."):
                            try:
                                sentiment, confidence = self.predict_sentiment(user_input, model_name, language_code)
                                
                                if sentiment:
                                    # æ˜¾ç¤ºç»“æœ
                                    st.success("åˆ†æå®Œæˆï¼")
                                    
                                    # ç»“æœå¡ç‰‡
                                    st.subheader("åˆ†æç»“æœ")
                                    col_result1, col_result2 = st.columns([1, 1])
                                    
                                    with col_result1:
                                        st.metric(
                                            label="æƒ…æ„Ÿå€¾å‘",
                                            value=sentiment,
                                            delta=f"ç½®ä¿¡åº¦: {confidence:.2%}"
                                        )
                                    
                                    with col_result2:
                                        st.progress(confidence)
                                        st.caption(f"ç½®ä¿¡åº¦: {confidence:.2%}")
                                    
                                    # æƒ…æ„Ÿå¯è§†åŒ–
                                    try:
                                        fig, ax = plt.subplots(figsize=(6, 4))
                                        labels = ['è´Ÿé¢', 'æ­£é¢']
                                        values = [1 - confidence, confidence] if sentiment == 'æ­£é¢' else [confidence, 1 - confidence]
                                        colors = ['#ff6b6b', '#4ecdc4']
                                        ax.bar(labels, values, color=colors)
                                        ax.set_ylim(0, 1)
                                        ax.set_ylabel('ç½®ä¿¡åº¦')
                                        ax.set_title('æƒ…æ„Ÿåˆ†æç½®ä¿¡åº¦åˆ†å¸ƒ')
                                        st.pyplot(fig)
                                    except Exception as e:
                                        st.warning(f"ç»˜åˆ¶æƒ…æ„Ÿåˆ†å¸ƒå›¾è¡¨å¤±è´¥: {e}")
                                    
                                    # è§¦å‘æ›´æ–°æ ‡å¿—ï¼Œç”¨äºé‡æ–°ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
                                    st.session_state.update_visualizations = True
                                    st.session_state.user_input = user_input
                                    st.session_state.user_sentiment = sentiment
                                    st.session_state.language_code = language_code
                                else:
                                    st.error(confidence)
                            except Exception as e:
                                st.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
                    else:
                        st.warning("è¯·è¾“å…¥å½±è¯„å†…å®¹")
            
            with col2:
                st.header("æ¨¡å‹ä¿¡æ¯")
                
                # æ¨¡å‹é€‰æ‹©ä¿¡æ¯
                st.info(f"å½“å‰æ¨¡å‹: **{model_name}**")
                
                # æ¨¡å‹åˆ—è¡¨
                st.subheader("å¯ç”¨æ¨¡å‹")
                for model in self.loaded_models.keys():
                    st.markdown(f"- {model}")
                
                # è¯´æ˜
                st.subheader("ä½¿ç”¨è¯´æ˜")
                st.markdown("1. åœ¨å·¦ä¾§é€‰æ‹©åˆé€‚çš„æ¨¡å‹")
                st.markdown("2. é€‰æ‹©å½±è¯„è¯­è¨€")
                st.markdown("3. åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥å½±è¯„å†…å®¹")
                st.markdown("4. ç‚¹å‡»'åˆ†ææƒ…æ„Ÿ'æŒ‰é’®")
                st.markdown("5. æŸ¥çœ‹æƒ…æ„Ÿåˆ†æç»“æœ")
            
            # ç»“æœå¯è§†åŒ–å±•ç¤º
            st.markdown("---")
            st.header("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ")
            
            # é€‰æ‹©è¦æŸ¥çœ‹çš„è¯„ä¼°ç»“æœç±»å‹
            visualization_type = st.selectbox(
                "é€‰æ‹©è¦æŸ¥çœ‹çš„è¯„ä¼°ç»“æœ",
                ['ROCæ›²çº¿', 'æ··æ·†çŸ©é˜µ', 'ç‰¹å¾é‡è¦æ€§', 'æƒ…æ„Ÿåˆ†å¸ƒ', 'è¯äº‘å›¾']
            )
            
            # åŠ¨æ€ç”Ÿæˆå¯è§†åŒ–ç»“æœ
            try:
                # ç¡®ä¿æ¯æ¬¡ç”Ÿæˆæ–°å›¾è¡¨å‰æ¸…é™¤ä¹‹å‰çš„å›¾è¡¨
                plt.close('all')
                
                # åˆå§‹åŒ–å˜é‡
                feature_names = None
                raw_texts = []
                tokens = []
                X_test = None
                y_test = None
                has_test_data = False
                
                # åŠ è½½æµ‹è¯•æ•°æ®ç”¨äºç”Ÿæˆå¯è§†åŒ–ç»“æœ
                processed_data_path = os.path.join(self.models_dir, 'processed_data.npz')
                if os.path.exists(processed_data_path):
                    data = np.load(processed_data_path, allow_pickle=True)
                    
                    # æ­£ç¡®åŠ è½½ç‰¹å¾åç§°ï¼ˆå§‹ç»ˆåŠ è½½ï¼Œæ— è®ºæ˜¯å¦ä½¿ç”¨æ›´æ–°æ•°æ®ï¼‰
                    if 'feature_names' in data:
                        feature_names_data = data['feature_names']
                        # å°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                        try:
                            feature_names = list(feature_names_data)
                        except:
                            feature_names = None
                    
                    # è·å–åŸå§‹æ–‡æœ¬æ•°æ®ç”¨äºè¯äº‘å›¾ï¼ˆå§‹ç»ˆåŠ è½½ï¼Œæ— è®ºæ˜¯å¦ä½¿ç”¨æ›´æ–°æ•°æ®ï¼‰
                    if 'raw_texts' in data:
                        try:
                            raw_texts = list(data['raw_texts'])
                        except:
                            raw_texts = []
                    
                    # è·å–åˆ†è¯åçš„æ–‡æœ¬ç”¨äºè¯äº‘å›¾ï¼ˆå§‹ç»ˆåŠ è½½ï¼Œæ— è®ºæ˜¯å¦ä½¿ç”¨æ›´æ–°æ•°æ®ï¼‰
                    if 'tokens' in data:
                        try:
                            tokens = list(data['tokens'])
                        except:
                            tokens = []
                    
                    # åŠ è½½åŸå§‹æµ‹è¯•æ•°æ®
                    X_test = data['X_test']
                    y_test = data['y_test']
                    has_test_data = True
                
                # æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦æœ‰æ›´æ–°åçš„æµ‹è¯•æ•°æ®
                if hasattr(st.session_state, 'X_test_updated') and hasattr(st.session_state, 'y_test_updated'):
                    # ä½¿ç”¨åŒ…å«ç”¨æˆ·è¾“å…¥çš„æµ‹è¯•æ•°æ®
                    X_test = st.session_state.X_test_updated
                    y_test = st.session_state.y_test_updated
                    has_test_data = True
                    
                    # å¦‚æœä¼šè¯çŠ¶æ€ä¸­æœ‰æ›´æ–°åçš„æ–‡æœ¬æ•°æ®ï¼Œåˆ™ä½¿ç”¨å®ƒ
                    if hasattr(st.session_state, 'raw_texts_updated'):
                        raw_texts = st.session_state.raw_texts_updated
                    if hasattr(st.session_state, 'tokens_updated'):
                        tokens = st.session_state.tokens_updated
                
                # è·å–å½“å‰é€‰ä¸­çš„æ¨¡å‹
                selected_model = self.loaded_models[model_name]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·è¾“å…¥çš„æ–°å½±è¯„éœ€è¦æ·»åŠ åˆ°æµ‹è¯•æ•°æ®ä¸­
                if hasattr(st.session_state, 'update_visualizations') and st.session_state.update_visualizations:
                    # è·å–ç”¨æˆ·è¾“å…¥çš„æ–°å½±è¯„å’Œæƒ…æ„Ÿæ ‡ç­¾
                    user_input = st.session_state.user_input
                    user_sentiment = st.session_state.user_sentiment
                    user_label = 1 if user_sentiment == 'æ­£é¢' else 0
                    
                    # è·å–æ­£ç¡®çš„è¯­è¨€ä»£ç 
                    if hasattr(st.session_state, 'language_code'):
                        session_language_code = st.session_state.language_code
                    else:
                        session_language_code = language_code
                    
                    # é¢„å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ–°å½±è¯„
                    user_vector = self.preprocess_text(user_input, language=session_language_code)
                    
                    # å°†æ–°å½±è¯„æ·»åŠ åˆ°æµ‹è¯•æ•°æ®ä¸­
                    if X_test is not None:
                        X_test = np.vstack([X_test, user_vector])
                        y_test = np.append(y_test, user_label)
                    else:
                        X_test = user_vector
                        y_test = np.array([user_label])
                    has_test_data = True
                    
                    # å°†æ–°å½±è¯„æ·»åŠ åˆ°åŸå§‹æ–‡æœ¬æ•°æ®ä¸­
                    raw_texts.append(user_input)
                    
                    # åˆ†è¯å¹¶æ·»åŠ åˆ°tokensæ•°æ®ä¸­
                    import jieba
                    user_tokens = ' '.join(jieba.cut(user_input))
                    tokens.append(user_tokens)
                    
                    # å°†æ›´æ–°åçš„æµ‹è¯•æ•°æ®ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ä¸­
                    st.session_state.X_test_updated = X_test
                    st.session_state.y_test_updated = y_test
                    st.session_state.raw_texts_updated = raw_texts
                    st.session_state.tokens_updated = tokens
                    
                    # é‡ç½®æ›´æ–°æ ‡å¿—
                    st.session_state.update_visualizations = False
                
                # å½“é€‰æ‹©ä¸åŒçš„å¯è§†åŒ–ç±»å‹æ—¶ï¼Œè§¦å‘é‡æ–°ç”Ÿæˆ
                if 'last_visualization_type' not in st.session_state or st.session_state.last_visualization_type != visualization_type:
                    st.session_state.last_visualization_type = visualization_type
                
                # ç”Ÿæˆé¢„æµ‹ç»“æœï¼ˆå¦‚æœæœ‰æµ‹è¯•æ•°æ®ï¼‰
                y_pred_proba = None
                y_pred = None
                if has_test_data and X_test is not None and y_test is not None:
                    if hasattr(selected_model, 'predict_proba'):
                        y_pred_proba = selected_model.predict_proba(X_test)[:, 1]
                    else:
                        y_pred_proba = selected_model.predict(X_test)
                    y_pred = (y_pred_proba > 0.5).astype(int)
                
                # æ ¹æ®é€‰æ‹©ç”Ÿæˆä¸åŒçš„å¯è§†åŒ–ç»“æœ
                if visualization_type == 'ROCæ›²çº¿':
                    st.subheader("ROCæ›²çº¿")
                    # ç»˜åˆ¶ROCæ›²çº¿
                    from sklearn.metrics import roc_curve, auc
                    
                    if has_test_data and y_test is not None and y_pred_proba is not None:
                        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                        roc_auc = auc(fpr, tpr)
                        
                        fig, ax = plt.subplots(figsize=(10, 8))
                        ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.4f})')
                        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                        ax.set_xlim([0.0, 1.0])
                        ax.set_ylim([0.0, 1.05])
                        ax.set_xlabel('å‡é˜³æ€§ç‡')
                        ax.set_ylabel('çœŸé˜³æ€§ç‡')
                        ax.set_title('ROCæ›²çº¿')
                        ax.legend(loc="lower right")
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)
                    else:
                        # å¦‚æœæ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥ç”Ÿæˆç®€åŒ–çš„ROCæ›²çº¿
                        st.info("æ­£åœ¨æ ¹æ®æ‚¨çš„è¾“å…¥ç”ŸæˆROCæ›²çº¿...")
                        # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„ROCæ›²çº¿ï¼Œå±•ç¤ºæ¨¡å‹çš„åŸºæœ¬æ€§èƒ½
                        fig, ax = plt.subplots(figsize=(10, 8))
                        # ç»˜åˆ¶ç†æƒ³ROCæ›²çº¿
                        ax.plot([0, 0.5, 1], [0, 0.9, 1], color='darkorange', lw=2, label='ç®€åŒ–ROCæ›²çº¿')
                        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºçŒœæµ‹')
                        ax.set_xlim([0.0, 1.0])
                        ax.set_ylim([0.0, 1.05])
                        ax.set_xlabel('å‡é˜³æ€§ç‡')
                        ax.set_ylabel('çœŸé˜³æ€§ç‡')
                        ax.set_title('åŸºäºç”¨æˆ·è¾“å…¥çš„ç®€åŒ–ROCæ›²çº¿')
                        ax.legend(loc="lower right")
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)
                
                elif visualization_type == 'æ··æ·†çŸ©é˜µ':
                    st.subheader("æ··æ·†çŸ©é˜µ")
                    # è®¡ç®—å¹¶ç»˜åˆ¶æ··æ·†çŸ©é˜µ
                    from sklearn.metrics import confusion_matrix
                    
                    if has_test_data and y_test is not None and y_pred is not None:
                        cm = confusion_matrix(y_test, y_pred)
                        
                        fig, ax = plt.subplots(figsize=(8, 6))
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['è´Ÿé¢', 'æ­£é¢'], yticklabels=['è´Ÿé¢', 'æ­£é¢'], ax=ax)
                        ax.set_xlabel('é¢„æµ‹æ ‡ç­¾')
                        ax.set_ylabel('çœŸå®æ ‡ç­¾')
                        ax.set_title('æ··æ·†çŸ©é˜µ')
                        st.pyplot(fig)
                    else:
                        # å¦‚æœæ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥ç”Ÿæˆç®€åŒ–çš„æ··æ·†çŸ©é˜µ
                        st.info("æ­£åœ¨æ ¹æ®æ‚¨çš„è¾“å…¥ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
                        # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æ··æ·†çŸ©é˜µï¼ŒåŸºäºç”¨æˆ·è¾“å…¥çš„é¢„æµ‹ç»“æœ
                        if hasattr(st.session_state, 'user_sentiment'):
                            user_sentiment = st.session_state.user_sentiment
                            user_label = 1 if user_sentiment == 'æ­£é¢' else 0
                            # åˆ›å»ºä¸€ä¸ª2x2çš„æ··æ·†çŸ©é˜µï¼Œå‡è®¾åªæœ‰ä¸€ä¸ªæ ·æœ¬
                            cm = np.array([[1 if user_label == 0 else 0, 0 if user_label == 0 else 0],
                                          [0 if user_label == 1 else 0, 1 if user_label == 1 else 0]])
                        else:
                            # é»˜è®¤æ··æ·†çŸ©é˜µ
                            cm = np.array([[1, 0], [0, 1]])
                        
                        fig, ax = plt.subplots(figsize=(8, 6))
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['è´Ÿé¢', 'æ­£é¢'], yticklabels=['è´Ÿé¢', 'æ­£é¢'], ax=ax)
                        ax.set_xlabel('é¢„æµ‹æ ‡ç­¾')
                        ax.set_ylabel('çœŸå®æ ‡ç­¾')
                        ax.set_title('åŸºäºç”¨æˆ·è¾“å…¥çš„ç®€åŒ–æ··æ·†çŸ©é˜µ')
                        st.pyplot(fig)
                
                elif visualization_type == 'ç‰¹å¾é‡è¦æ€§':
                    st.subheader("ç‰¹å¾é‡è¦æ€§")
                    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
                    if feature_names is not None:
                        try:
                            fig, ax = plt.subplots(figsize=(12, 8))
                            
                            if hasattr(selected_model, 'feature_importances_'):
                                importances = selected_model.feature_importances_
                            elif hasattr(selected_model, 'coef_'):
                                importances = np.abs(selected_model.coef_[0])
                            else:
                                st.warning("å½“å‰æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§è®¡ç®—")
                                importances = None
                            
                            if importances is not None:
                                # è·å–ç‰¹å¾é‡è¦æ€§æ’åº
                                indices = np.argsort(importances)[::-1][:20]
                                top_features = [feature_names[i] for i in indices]
                                top_importances = importances[indices]
                                
                                ax.barh(range(len(top_features)), top_importances, align='center')
                                ax.set_yticks(range(len(top_features)))
                                ax.set_yticklabels(top_features)
                                ax.set_xlabel('ç‰¹å¾é‡è¦æ€§')
                                ax.set_ylabel('ç‰¹å¾')
                                ax.set_title('ç‰¹å¾é‡è¦æ€§æ’åº')
                                ax.invert_yaxis()
                                st.pyplot(fig)
                        except Exception as e:
                            st.warning(f"ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾å¤±è´¥: {e}")
                    else:
                        st.warning("æœªæ‰¾åˆ°ç‰¹å¾åç§°æ•°æ®")
                
                elif visualization_type == 'æƒ…æ„Ÿåˆ†å¸ƒ':
                    st.subheader("æƒ…æ„Ÿåˆ†å¸ƒ")
                    # ç»˜åˆ¶æƒ…æ„Ÿåˆ†å¸ƒ
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
                    
                    if has_test_data and y_test is not None and y_pred is not None:
                        # çœŸå®æ ‡ç­¾åˆ†å¸ƒ
                        label_counts = pd.Series(y_test).value_counts()
                        label_counts.index = label_counts.index.map({0: 'è´Ÿé¢', 1: 'æ­£é¢'})
                        ax1.pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%', startangle=90)
                        ax1.set_title('çœŸå®æƒ…æ„Ÿåˆ†å¸ƒ')
                        ax1.axis('equal')
                        
                        # é¢„æµ‹ç»“æœåˆ†å¸ƒ
                        pred_counts = pd.Series(y_pred).value_counts()
                        pred_counts.index = pred_counts.index.map({0: 'è´Ÿé¢', 1: 'æ­£é¢'})
                        ax2.pie(pred_counts.values, labels=pred_counts.index, autopct='%1.1f%%', startangle=90)
                        ax2.set_title('é¢„æµ‹æƒ…æ„Ÿåˆ†å¸ƒ')
                        ax2.axis('equal')
                    else:
                        # ä½¿ç”¨é»˜è®¤åˆ†å¸ƒæˆ–ç”¨æˆ·è¾“å…¥ç”Ÿæˆç®€åŒ–çš„æƒ…æ„Ÿåˆ†å¸ƒ
                        st.info("æ­£åœ¨æ ¹æ®æ‚¨çš„è¾“å…¥ç”Ÿæˆæƒ…æ„Ÿåˆ†å¸ƒ...")
                        # çœŸå®æ ‡ç­¾åˆ†å¸ƒï¼ˆé»˜è®¤ï¼‰
                        ax1.pie([50, 50], labels=['è´Ÿé¢', 'æ­£é¢'], autopct='%1.1f%%', startangle=90)
                        ax1.set_title('é»˜è®¤çœŸå®æƒ…æ„Ÿåˆ†å¸ƒ')
                        ax1.axis('equal')
                        
                        # é¢„æµ‹ç»“æœåˆ†å¸ƒï¼ˆåŸºäºç”¨æˆ·è¾“å…¥ï¼‰
                        if hasattr(st.session_state, 'user_sentiment'):
                            user_sentiment = st.session_state.user_sentiment
                            if user_sentiment == 'æ­£é¢':
                                ax2.pie([20, 80], labels=['è´Ÿé¢', 'æ­£é¢'], autopct='%1.1f%%', startangle=90)
                            else:
                                ax2.pie([80, 20], labels=['è´Ÿé¢', 'æ­£é¢'], autopct='%1.1f%%', startangle=90)
                        else:
                            ax2.pie([50, 50], labels=['è´Ÿé¢', 'æ­£é¢'], autopct='%1.1f%%', startangle=90)
                        ax2.set_title('åŸºäºç”¨æˆ·è¾“å…¥çš„é¢„æµ‹æƒ…æ„Ÿåˆ†å¸ƒ')
                        ax2.axis('equal')
                    
                    st.pyplot(fig)
                
                elif visualization_type == 'è¯äº‘å›¾':
                    st.subheader("è¯äº‘å›¾")
                    # ç»˜åˆ¶è¯äº‘å›¾
                    try:
                        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬æ•°æ®ï¼Œç¡®ä¿åŒ…å«ç”¨æˆ·è¾“å…¥çš„æ–°æ–‡æœ¬
                        all_texts = []
                        
                        # æ·»åŠ åŸå§‹æ–‡æœ¬æ•°æ®
                        if raw_texts:
                            all_texts.extend([str(text) for text in raw_texts if text.strip()])
                        if tokens:
                            all_texts.extend([str(text) for text in tokens if text.strip()])
                        
                        # æ·»åŠ ç”¨æˆ·è¾“å…¥çš„æ–°æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
                        if hasattr(st.session_state, 'user_input'):
                            all_texts.append(str(st.session_state.user_input))
                        
                        # å¦‚æœæ²¡æœ‰æ–‡æœ¬æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬
                        if not all_texts:
                            all_texts.append("è¿™æ˜¯ä¸€ä¸ªé»˜è®¤çš„å½±è¯„ç¤ºä¾‹ï¼Œç”¨äºç”Ÿæˆè¯äº‘å›¾ã€‚ç”µå½±éå¸¸ç²¾å½©ï¼Œå‰§æƒ…ç´§å‡‘ï¼Œæ¼”å‘˜è¡¨æ¼”å‡ºè‰²ï¼Œæ¨èå¤§å®¶è§‚çœ‹ã€‚")
                        
                        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
                        all_text = ' '.join(all_texts)
                        
                        # ç¡®ä¿æœ‰æ–‡æœ¬æ•°æ®
                        if all_text.strip():
                            # åªä½¿ç”¨ä¸­æ–‡åˆ†è¯
                            import jieba
                            words = jieba.cut(all_text)
                            words = [word for word in words if len(word) > 1 and word.strip()]
                            word_freq = pd.Series(words).value_counts().to_dict()
                            
                            # ç”Ÿæˆè¯äº‘å›¾
                            if word_freq:
                                from wordcloud import WordCloud
                                
                                # æ£€æŸ¥å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä»…ä½¿ç”¨ä¸­æ–‡å­—ä½“
                                font_path = None
                                if os.path.exists('simhei.ttf'):
                                    font_path = 'simhei.ttf'
                                elif os.path.exists('C:/Windows/Fonts/simhei.ttf'):
                                    font_path = 'C:/Windows/Fonts/simhei.ttf'
                                elif os.path.exists('C:/Windows/Fonts/msyh.ttc'):
                                    font_path = 'C:/Windows/Fonts/msyh.ttc'
                                
                                # åˆ›å»ºè¯äº‘å¯¹è±¡
                                wordcloud = WordCloud(font_path=font_path, 
                                                    background_color='white', 
                                                    max_words=200, 
                                                    max_font_size=100, 
                                                    width=800, 
                                                    height=400)
                                
                                # ç”Ÿæˆè¯äº‘
                                wordcloud.generate_from_frequencies(word_freq)
                                
                                # ç»˜åˆ¶è¯äº‘å›¾
                                fig, ax = plt.subplots(figsize=(12, 8))
                                ax.imshow(wordcloud, interpolation='bilinear')
                                ax.set_title('å®æ—¶è¯äº‘å›¾')
                                ax.axis('off')
                                st.pyplot(fig)
                                
                                # ä¿å­˜è¯äº‘å›¾åˆ°ä¼šè¯çŠ¶æ€ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
                                st.session_state.wordcloud_fig = fig
                            else:
                                st.warning("è¯é¢‘ç»Ÿè®¡ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯äº‘å›¾")
                        else:
                            st.warning("æœªæ‰¾åˆ°æ–‡æœ¬æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆè¯äº‘å›¾")
                    except Exception as e:
                        st.warning(f"ç”Ÿæˆè¯äº‘å›¾å¤±è´¥: {e}")
                        st.exception(e)
            except Exception as e:
                st.warning(f"ç”Ÿæˆå¯è§†åŒ–ç»“æœå¤±è´¥: {e}")
                st.exception(e)
        except Exception as e:
            st.error(f"åº”ç”¨å‡ºç°é”™è¯¯: {e}")
            st.exception(e)
    
    def run(self):
        """è¿è¡ŒGUI"""
        self.display_results()

if __name__ == "__main__":
    gui = SentimentAnalyzerGUI()
    gui.run()
